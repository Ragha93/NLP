{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5678c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim,nltk,string,os,zipfile\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer,LancasterStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Dense,SimpleRNN,LSTM,GRU\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adagrad,Adam,SGD,RMSprop\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1377e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\raghav\\\\Desktop\\\\Files\\\\Jupyter_Notebook_Files\\\\NLP\\\\Word Embedding - Word2Vec & GloVe\\\\Botdata.csv',encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c09ff93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hello! how can i help you ?',\n",
       "       'I am your virtual learning assistant',\n",
       "       'I hope I was able to assist you, Good Bye',\n",
       "       'Link: Machine Learning wiki ', 'Link: Neural Nets wiki',\n",
       "       'Link: Olympus wiki', 'Please use respectful words',\n",
       "       'Transferring the request to your PM'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Responses.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd1f25cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Intro', 'Bot', 'Exit', 'SL', 'NN', 'Olympus', 'Profane', 'Ticket'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Tag.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73641743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Cleaning(x):\n",
    "    Complete_data = []\n",
    "    for i in x:\n",
    "        single_row = []\n",
    "        for j in word_tokenize(i):\n",
    "            if j.lower() not in string.punctuation:\n",
    "                single_row.append(j.lower())\n",
    "        Complete_data.append(single_row)            \n",
    "    return Complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29ef628",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = Data_Cleaning(df['Pattern'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9cefb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hi'],\n",
       " ['how', 'are', 'you'],\n",
       " ['hello', 'there'],\n",
       " ['hello'],\n",
       " ['whats', 'up'],\n",
       " ['hey'],\n",
       " ['yo'],\n",
       " ['listen'],\n",
       " ['please', 'help', 'me'],\n",
       " ['hi', 'there'],\n",
       " ['hello', 'bot'],\n",
       " ['whats', 'up', 'for', 'today'],\n",
       " ['hello', 'guys', 'i', 'need', 'a', 'help'],\n",
       " ['hey', 'there'],\n",
       " ['i', 'have', 'a', 'quick', 'question'],\n",
       " ['how', 'to', 'start'],\n",
       " ['online'],\n",
       " ['hey', 'ya'],\n",
       " ['talking', 'to', 'you', 'for', 'first', 'time'],\n",
       " ['anyone', 'there'],\n",
       " ['i', 'am', 'here', 'to', 'get', 'help'],\n",
       " ['someone', 'help', 'me', 'please'],\n",
       " ['ello'],\n",
       " ['wassuppp'],\n",
       " ['whats', 'happening', 'around', 'the', 'portal'],\n",
       " ['i', 'have', 'few', 'quick', 'questions'],\n",
       " ['i', 'need', 'a', 'help'],\n",
       " ['there'],\n",
       " ['what', 'is', 'your', 'name'],\n",
       " ['who', 'are', 'you'],\n",
       " ['how', 'do', 'they', 'call', 'you'],\n",
       " ['do', 'i', 'know', 'you'],\n",
       " ['who', 'is', 'there'],\n",
       " ['who', 'is', 'you'],\n",
       " ['your', 'name', 'please'],\n",
       " ['may', 'i', 'know', 'your', 'name'],\n",
       " ['speak', 'up'],\n",
       " ['are', 'you', 'a', 'human'],\n",
       " ['do', 'you', 'answer', 'questions'],\n",
       " ['who', 'is', 'learning', 'assistant'],\n",
       " ['who', 'is', 'supporting', 'assistant'],\n",
       " ['any', 'assistant'],\n",
       " ['whos', 'that', 'i', 'am', 'speaking', 'to'],\n",
       " ['may', 'i', 'know', 'who', 'you', 'are'],\n",
       " ['who', 'is', 'speaking'],\n",
       " ['are', 'you', 'a', 'bot', 'or', 'a', 'human'],\n",
       " ['who', 'am', 'i', 'speaking', 'to', 'a', 'bot', 'or', 'a', 'person'],\n",
       " ['how', 'do', 'i', 'call', 'you'],\n",
       " ['can', 'i', 'call', 'you', 'vla'],\n",
       " ['are', 'you', 'my', 'teacher'],\n",
       " ['they', 'call', 'you', 'with', 'what'],\n",
       " ['i', 'would', 'like', 'to', 'know', 'about', 'you'],\n",
       " ['you', 'are', 'what'],\n",
       " ['thank', 'you'],\n",
       " ['thanks'],\n",
       " ['cya'],\n",
       " ['see', 'you'],\n",
       " ['later'],\n",
       " ['see', 'you', 'later'],\n",
       " ['goodbye'],\n",
       " ['i', 'am', 'leaving'],\n",
       " ['have', 'a', 'good', 'day'],\n",
       " ['you', 'helped', 'me'],\n",
       " ['thanks', 'a', 'lot'],\n",
       " ['thanks', 'a', 'ton'],\n",
       " ['you', 'are', 'the', 'best'],\n",
       " ['great', 'help'],\n",
       " ['too', 'good'],\n",
       " ['you', 'are', 'a', 'good', 'learning', 'buddy'],\n",
       " ['ok', 'i', 'am', 'good'],\n",
       " ['alright', 'i', \"'m\", 'good'],\n",
       " ['thanks', 'for', 'help'],\n",
       " ['doubt', 'cleared'],\n",
       " ['exit'],\n",
       " ['quit', 'cleared'],\n",
       " ['that', 'â€™', 's', 'a', 'wrap'],\n",
       " ['bye', 'bye'],\n",
       " ['ty'],\n",
       " ['i', 'think', 'you', 'cleared', 'my', 'doubt'],\n",
       " ['you', 'can', 'answer', 'well'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'a',\n",
       "  'good',\n",
       "  'replacement',\n",
       "  'for',\n",
       "  'humans',\n",
       "  'to',\n",
       "  'clarify',\n",
       "  'doubts'],\n",
       " ['i',\n",
       "  'think',\n",
       "  'i',\n",
       "  'am',\n",
       "  'good',\n",
       "  'with',\n",
       "  'your',\n",
       "  'answer',\n",
       "  'it',\n",
       "  'seems',\n",
       "  'to',\n",
       "  'be',\n",
       "  'clear',\n",
       "  'and',\n",
       "  'i',\n",
       "  'can',\n",
       "  'do',\n",
       "  'this',\n",
       "  'now'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'svm'],\n",
       " ['explain', 'me', 'how', 'machine', 'learning', 'works'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'naive', 'bayes'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'logistic', 'regression'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'ensemble', 'techb=niques'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'knn'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'knn', 'imputer'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'cross', 'validation'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'boosting'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'random', 'forest'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'ada', 'boosting'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'gradient', 'boosting'],\n",
       " ['machine', 'learning'],\n",
       " ['ml'],\n",
       " ['sl'],\n",
       " ['supervised', 'learning'],\n",
       " ['knn'],\n",
       " ['logistic', 'regression'],\n",
       " ['regression'],\n",
       " ['classification'],\n",
       " ['naive', 'bayes'],\n",
       " ['nb'],\n",
       " ['ensemble', 'techniques'],\n",
       " ['bagging'],\n",
       " ['boosting'],\n",
       " ['ada', 'boosting'],\n",
       " ['ada'],\n",
       " ['gradient', 'boosting'],\n",
       " ['hyper', 'parameters'],\n",
       " ['what', 'is', 'deep', 'learning'],\n",
       " ['unable', 'to', 'understand', 'deep', 'learning'],\n",
       " ['explain', 'me', 'how', 'deep', 'learning', 'works'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'deep', 'learning'],\n",
       " ['not', 'able', 'to', 'understand', 'neural', 'nets'],\n",
       " ['very', 'diffult', 'to', 'understand', 'neural', 'nets'],\n",
       " ['unable', 'to', 'understand', 'neural', 'nets'],\n",
       " ['ann'],\n",
       " ['artificial', 'intelligence'],\n",
       " ['artificial', 'neural', 'networks'],\n",
       " ['weights'],\n",
       " ['activation', 'function'],\n",
       " ['hidden', 'layers'],\n",
       " ['softmax'],\n",
       " ['sigmoid'],\n",
       " ['relu'],\n",
       " ['otimizer'],\n",
       " ['forward', 'propagation'],\n",
       " ['backward', 'propagation'],\n",
       " ['epochs'],\n",
       " ['epoch'],\n",
       " ['what', 'is', 'an', 'epoch'],\n",
       " ['adam'],\n",
       " ['sgd'],\n",
       " ['what', 'is', 'ai'],\n",
       " ['can', 'you', 'think'],\n",
       " ['how', 'does', 'machines', 'think'],\n",
       " ['perceptron'],\n",
       " ['what', 'is', 'early', 'stopping'],\n",
       " ['olympus'],\n",
       " ['explain', 'me', 'how', 'olympus', 'works'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'olympus'],\n",
       " ['olympus', 'window', 'not', 'working'],\n",
       " ['no', 'access', 'to', 'olympus'],\n",
       " ['unable', 'to', 'see', 'link', 'in', 'olympus'],\n",
       " ['no', 'link', 'visible', 'on', 'olympus'],\n",
       " ['whom', 'to', 'contact', 'for', 'olympus'],\n",
       " ['lot', 'of', 'problem', 'with', 'olympus'],\n",
       " ['olypus', 'is', 'not', 'a', 'good', 'tool'],\n",
       " ['lot', 'of', 'problems', 'with', 'olympus'],\n",
       " ['how', 'to', 'use', 'olympus'],\n",
       " ['teach', 'me', 'olympus'],\n",
       " ['portal', 'not', 'working'],\n",
       " ['give', 'me', 'portal', 'link'],\n",
       " ['olympus', 'portal'],\n",
       " ['pg', 'portal'],\n",
       " ['course', 'portal'],\n",
       " ['poc', 'for', 'olympus', 'portal'],\n",
       " ['help', 'me', 'on', 'olympus', 'portal'],\n",
       " ['tell', 'me', 'how', 'this', 'pg', 'works'],\n",
       " ['may', 'i', 'have', 'the', 'wiki', 'page', 'for', 'this', 'pg', 'course'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'an',\n",
       "  'ongoing',\n",
       "  'problem',\n",
       "  'with',\n",
       "  'the',\n",
       "  'site',\n",
       "  'is',\n",
       "  'it',\n",
       "  'down'],\n",
       " ['do', 'you', 'have', 'wikipedia', 'for', 'this', 'pg'],\n",
       " ['which', 'site', 'helps', 'in', 'displaying', 'the', 'course'],\n",
       " ['do', 'i', 'need', 'to', 'login', 'to', 'use', 'this', 'course'],\n",
       " ['is', 'there', 'any', 'portal', 'to', 'display', 'all', 'the', 'courses'],\n",
       " ['where', 'do', 'i', 'see', 'my', 'rank'],\n",
       " ['where', 'shall', 'i', 'see', 'my', 'marks'],\n",
       " ['what', 'the', 'hell', 'are', 'you', 'talking', 'about'],\n",
       " ['bloody', 'stupid', 'bot'],\n",
       " ['do', 'you', 'think', 'you', 'are', 'very', 'smart'],\n",
       " ['screw', 'you'],\n",
       " ['i', 'hate', 'you'],\n",
       " ['you', 'are', 'stupid'],\n",
       " ['jerk'],\n",
       " ['you', 'are', 'a', 'joke'],\n",
       " ['useless', 'piece', 'of', 'shit'],\n",
       " ['get', 'lost'],\n",
       " ['you', 'stupid'],\n",
       " ['dont', 'talk', 'like', 'an', 'idiot'],\n",
       " ['do', 'you', 'have', 'sense'],\n",
       " ['senseless', 'creature'],\n",
       " ['shut', 'your', 'mouth'],\n",
       " ['dont', 'speak', 'like', 'a', 'dummy'],\n",
       " ['you', 'stupid', 'dummy'],\n",
       " ['shut', 'up'],\n",
       " ['you', 'deserve', 'bad', 'words', 'and', 'bad', 'shit', 'only'],\n",
       " ['shut', 'your', 'useless', 'responses'],\n",
       " ['you', 'are', 'just', 'a', 'junk', 'that', 'has', 'no', 'value'],\n",
       " ['bloody'],\n",
       " ['stupid'],\n",
       " ['shit'],\n",
       " ['dum'],\n",
       " ['i', 'said', 'shutttt', 'upppp'],\n",
       " ['get', 'out', 'of', 'my', 'way'],\n",
       " ['you', 'are', 'a', 'complete', 'mess'],\n",
       " ['messy', 'creature'],\n",
       " ['my', 'problem', 'is', 'not', 'solved'],\n",
       " ['you', 'did', 'not', 'help', 'me'],\n",
       " ['not', 'a', 'good', 'solution'],\n",
       " ['bad', 'solution'],\n",
       " ['not', 'good', 'solution'],\n",
       " ['no', 'help'],\n",
       " ['wasted', 'my', 'time'],\n",
       " ['useless', 'bot'],\n",
       " ['create', 'a', 'ticket'],\n",
       " ['i', 'dont', 'see', 'a', 'solution'],\n",
       " ['where', 'is', 'the', 'solution'],\n",
       " ['connect', 'me', 'to', 'a', 'human'],\n",
       " ['want', 'to', 'talk', 'to', 'a', 'person'],\n",
       " ['this', 'is', 'not', 'an', 'answer'],\n",
       " ['its', 'not', 'a', 'solution'],\n",
       " ['this', 'is', 'not', 'a', 'solution'],\n",
       " ['please', 'push', 'it', 'to', 'a', 'human'],\n",
       " ['i', 'do', 'not', 'want', 'to', 'talk', 'to', 'a', 'bot'],\n",
       " ['do', 'not', 'connect', 'to', 'a', 'bot'],\n",
       " ['someone', 'please', 'answer', 'my', 'question'],\n",
       " ['can',\n",
       "  'you',\n",
       "  'please',\n",
       "  'connect',\n",
       "  'me',\n",
       "  'to',\n",
       "  'someone',\n",
       "  'who',\n",
       "  'can',\n",
       "  'talk'],\n",
       " ['i', 'would', 'need', 'a', 'better', 'help'],\n",
       " ['i', 'need', 'my', 'query', 'to', 'be', 'manually', 'handled'],\n",
       " ['i', 'would', 'need', 'a', 'real', 'assistant'],\n",
       " ['this', 'aint', 'helping', 'me', 'get', 'to', 'the', 'solution'],\n",
       " ['can', 'i', 'get', 'a', 'better', 'solution'],\n",
       " ['can', 'i', 'get', 'a', 'better', 'answer'],\n",
       " ['i',\n",
       "  'can',\n",
       "  'not',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'a',\n",
       "  'bot',\n",
       "  'i',\n",
       "  'need',\n",
       "  'human',\n",
       "  'intervention'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'intrested',\n",
       "  'in',\n",
       "  'talking',\n",
       "  'to',\n",
       "  'an',\n",
       "  'automated',\n",
       "  'computer'],\n",
       " ['somebody', 'please', 'help', 'me'],\n",
       " ['good', 'morning'],\n",
       " ['good', 'afternoon'],\n",
       " ['good', 'evening'],\n",
       " ['someone', 'there'],\n",
       " ['your', 'are'],\n",
       " ['you', 'are'],\n",
       " ['are', 'you', 'their', 'assistant'],\n",
       " ['what', 'are', 'you'],\n",
       " ['whats', 'your', 'name'],\n",
       " ['how', 'am', 'i', 'supposed', 'to', 'call', 'you'],\n",
       " ['my', 'doubt', 'is', 'cleared'],\n",
       " ['my', 'issue', 'is', 'rectified'],\n",
       " ['im', 'good'],\n",
       " ['its', 'clear'],\n",
       " ['all', 'clear'],\n",
       " ['perfect', 'this', 'is', 'what', 'i', 'need'],\n",
       " ['this', 'clears', 'my', 'doubt'],\n",
       " ['what', 'is', 'svm', 'that', 'is', 'the', 'support', 'vector', 'machines'],\n",
       " ['what', 'is', 'ml'],\n",
       " ['what', 'is', 'machine', 'learning'],\n",
       " ['its', 'about', 'machine', 'learning'],\n",
       " ['its', 'about', 'ml'],\n",
       " ['ml', 'technique', 'doubts'],\n",
       " ['i', 'have', 'doubts', 'on', 'ml'],\n",
       " ['i', 'have', 'doubts', 'on', 'ml', 'techniques'],\n",
       " ['i', 'have', 'doubt', 'on', 'algorithms'],\n",
       " ['ml', 'algorithms', 'doubt'],\n",
       " ['can', 'you', 'help', 'me', 'understand', 'the', 'ml', 'algorithms'],\n",
       " ['i', 'just', 'cant', 'understand', 'the', 'ann'],\n",
       " ['what', 'is', 'ann'],\n",
       " ['ann'],\n",
       " ['what', 'does', 'ann', 'do'],\n",
       " ['advantages', 'of', 'ann'],\n",
       " ['is', 'ann', 'efficient'],\n",
       " ['what', 'is', 'universal', 'approximation'],\n",
       " ['neural', 'networks'],\n",
       " ['what', 'is', 'nn'],\n",
       " ['i', 'would', 'like', 'some', 'support', 'on', 'nn'],\n",
       " ['i', 'would', 'like', 'some', 'support', 'on', 'ann'],\n",
       " ['somebody', 'please', 'help', 'me', 'understand', 'ann'],\n",
       " ['someone', 'can', 'explain', 'how', 'the', 'portal', 'works'],\n",
       " ['where', 'is', 'the', 'aiml', 'portal'],\n",
       " ['where', 'do', 'i', 'see', 'the', 'course', 'materials'],\n",
       " ['where',\n",
       "  'do',\n",
       "  'i',\n",
       "  'see',\n",
       "  'the',\n",
       "  'recordings',\n",
       "  'of',\n",
       "  'the',\n",
       "  'mentor',\n",
       "  'session'],\n",
       " ['what', 'are', 'the', 'features', 'of', 'the', 'olympus', 'portal'],\n",
       " ['how', 'do', 'i', 'access', 'the', 'portal', 'to', 'learn'],\n",
       " ['shut', 'your', 'answers', 'right', 'now'],\n",
       " ['shitty', 'bot'],\n",
       " ['just', 'cant', 'stand', 'your', 'stupid', 'responses'],\n",
       " ['get', 'lost', 'you', 'idiotic', 'bot'],\n",
       " ['can', 'someone', 'please', 'help', 'me', 'with', 'better', 'answer'],\n",
       " ['is', 'there', 'a', 'human', 'to', 'clear', 'my', 'doubts'],\n",
       " ['please', 'send', 'in', 'some', 'human', 'to', 'clear', 'my', 'doubts'],\n",
       " ['please', 'get', 'some', 'live', 'person', 'to', 'clear', 'my', 'doubts'],\n",
       " ['your',\n",
       "  'answers',\n",
       "  'are',\n",
       "  'not',\n",
       "  'clear',\n",
       "  'and',\n",
       "  'correct',\n",
       "  'i',\n",
       "  'need',\n",
       "  'help'],\n",
       " ['i', 'need', 'better', 'answers', 'to', 'my', 'questions'],\n",
       " ['these', 'are', 'not', 'clear', 'answers'],\n",
       " ['you',\n",
       "  'please',\n",
       "  'connect',\n",
       "  'this',\n",
       "  'conversation',\n",
       "  'to',\n",
       "  'a',\n",
       "  'live',\n",
       "  'human',\n",
       "  'conversation']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a211119",
   "metadata": {},
   "source": [
    "# We will create multiple vectorization techniques\n",
    "## 1. Word2Vec (Self Trained)\n",
    "## 2. Word2Vec (Pre-Trained)\n",
    "## 3. GloVe(Pre-Trained)\n",
    "\n",
    "## The above 3 data sources will be used on RNN, LSTM and GRU. We will have 9 different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649789b5",
   "metadata": {},
   "source": [
    "# 1. Word2Vec (Self Trained) - w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "279bf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(cleaned_data,window=5,min_count=1,sg=0,vector_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af626364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0071556 ,  0.00637592, -0.00201847, -0.00474921,  0.00495806,\n",
       "       -0.00790987,  0.00294074,  0.00973763,  0.00686235, -0.00312551,\n",
       "        0.00236688,  0.00485499,  0.00956698, -0.00275564,  0.00136494,\n",
       "       -0.0042223 , -0.00316549,  0.00081706,  0.00216475, -0.00543462,\n",
       "        0.00426822, -0.00508734, -0.00459894, -0.00905573,  0.00760234,\n",
       "        0.00430341, -0.00228152,  0.00843985,  0.00194922, -0.00988891,\n",
       "       -0.00773005, -0.00423402, -0.00730689,  0.00733085,  0.00502309,\n",
       "        0.00208817, -0.00063066, -0.00746233,  0.00606645, -0.00528325,\n",
       "       -0.00266641, -0.00587983, -0.00223673, -0.00931764,  0.00333597,\n",
       "       -0.00745668,  0.00673162, -0.00749905, -0.00584616,  0.00012663,\n",
       "       -0.00791986,  0.00530259, -0.00419767,  0.00035033,  0.00778899,\n",
       "        0.00316128, -0.00018578,  0.00768974, -0.00019279,  0.00564487,\n",
       "        0.00597251, -0.00798886,  0.00196761, -0.00948583, -0.00150069,\n",
       "        0.00867612, -0.00244304, -0.00474332,  0.00266606,  0.00733291,\n",
       "        0.00654233, -0.00650615,  0.00706908,  0.00757643, -0.00531804,\n",
       "       -0.00118991, -0.00057014, -0.00940131, -0.00243374,  0.00976549,\n",
       "       -0.00266312, -0.00767391, -0.0043358 , -0.00948335,  0.00195622,\n",
       "        0.00599837,  0.0007838 , -0.00342875,  0.00954343, -0.00933341,\n",
       "       -0.00447667, -0.00972698,  0.00961212, -0.0018554 , -0.00526554,\n",
       "       -0.00787931,  0.00823617, -0.00297391, -0.00579429,  0.00371354],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.get_vector('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e927ddf4",
   "metadata": {},
   "source": [
    "# 2. Word2Vec (Pre-Trained) - pretrained_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aae1a5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36121afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_w2v = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39921314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.082078  , -0.049793  , -0.0075161 , -0.020323  , -0.0092538 ,\n",
       "       -0.072095  ,  0.033758  , -0.078571  ,  0.08059   , -0.052607  ,\n",
       "       -0.020787  , -0.071582  ,  0.10044   ,  0.018694  , -0.0029067 ,\n",
       "        0.039427  ,  0.14199   , -0.051042  ,  0.025533  ,  0.039338  ,\n",
       "       -0.072977  ,  0.056744  ,  0.027786  ,  0.044195  ,  0.055468  ,\n",
       "       -0.04315   ,  0.083226  , -0.10961   ,  0.047717  , -0.0097087 ,\n",
       "        0.075673  ,  0.099839  ,  0.076693  ,  0.0033689 ,  0.0080532 ,\n",
       "        0.07054   , -0.018284  ,  0.010139  , -0.030658  ,  0.088302  ,\n",
       "       -0.096714  , -0.12911   ,  0.052357  , -0.15232   ,  0.030007  ,\n",
       "        0.059222  ,  0.059283  , -0.066301  ,  0.049369  ,  0.049344  ,\n",
       "       -0.065009  , -0.0059145 ,  0.028648  , -0.032529  , -0.080934  ,\n",
       "       -0.066755  , -0.0057464 ,  0.00093308, -0.039737  ,  0.099084  ,\n",
       "        0.018779  ,  0.027044  ,  0.1356    , -0.041382  ,  0.041289  ,\n",
       "       -0.048331  , -0.067529  , -0.063287  ,  0.11987   , -0.058627  ,\n",
       "       -0.011716  , -0.1896    ,  0.019796  , -0.095828  ,  0.0084474 ,\n",
       "        0.049721  , -0.034435  ,  0.022483  , -0.016258  , -0.058899  ,\n",
       "       -0.047158  ,  0.098113  , -0.084294  ,  0.10779   , -0.066017  ,\n",
       "        0.027579  , -0.18174   , -0.10589   , -0.16668   , -0.049522  ,\n",
       "       -0.078398  ,  0.072497  , -0.0071685 ,  0.071982  ,  0.026604  ,\n",
       "        0.035239  , -0.024083  , -0.046204  , -0.031851  , -0.075672  ,\n",
       "        0.072568  , -0.017568  ,  0.052462  , -0.052618  ,  0.11855   ,\n",
       "       -0.14913   ,  0.00063183,  0.0044355 ,  0.027639  ,  0.0268    ,\n",
       "        0.032626  ,  0.15665   , -0.010503  ,  0.012448  , -0.049496  ,\n",
       "        0.048093  , -0.10074   ,  0.021478  , -0.011534  ,  0.069125  ,\n",
       "        0.046361  , -0.054978  ,  0.0034998 ,  0.0030935 , -0.0051331 ,\n",
       "        0.094233  ,  0.018363  , -0.11387   ,  0.012277  ,  0.10322   ,\n",
       "       -0.0099157 , -0.025959  ,  0.050113  , -0.013099  , -0.012859  ,\n",
       "       -0.066962  ,  0.093075  ,  0.0022104 , -0.063628  ,  0.13933   ,\n",
       "       -0.00040314, -0.064966  ,  0.078216  ,  0.040021  , -0.064672  ,\n",
       "        0.034761  , -0.055548  ,  0.10576   ,  0.046467  , -0.078019  ,\n",
       "        0.040537  ,  0.031695  ,  0.064853  , -0.028169  ,  0.02509   ,\n",
       "       -0.06825   , -0.034429  ,  0.025494  ,  0.14007   ,  0.029333  ,\n",
       "       -0.011186  , -0.01537   , -0.034184  ,  0.039416  ,  0.051572  ,\n",
       "        0.027964  ,  0.023956  , -0.028341  ,  0.01559   ,  0.13925   ,\n",
       "       -0.049858  ,  0.060491  , -0.022136  ,  0.020515  , -0.063524  ,\n",
       "        0.11755   , -0.051997  ,  0.022519  ,  0.037795  ,  0.047017  ,\n",
       "        0.0088855 ,  0.024206  , -0.080228  , -0.066294  , -0.011232  ,\n",
       "       -0.09499   ,  0.026573  ,  0.147     , -0.017787  , -0.02035   ,\n",
       "       -0.0024519 ,  0.073262  , -0.085423  ,  0.022539  ,  0.010292  ,\n",
       "       -0.0056318 , -0.024673  , -0.04292   , -0.0093779 ,  0.034066  ,\n",
       "       -0.18153   , -0.0081031 , -0.0099283 ,  0.040224  , -0.034956  ,\n",
       "        0.00074665,  0.0046748 , -0.020361  ,  0.10863   , -0.029601  ,\n",
       "        0.14132   , -0.061211  , -0.020715  , -0.093348  ,  0.036147  ,\n",
       "        0.0092115 , -0.0035311 ,  0.046916  ,  0.10218   , -0.0084185 ,\n",
       "       -0.10898   , -0.017493  , -0.090218  ,  0.14205   , -0.068365  ,\n",
       "        0.043254  ,  0.10903   ,  0.10452   , -0.027758  ,  0.028394  ,\n",
       "       -0.063309  , -0.089111  , -0.1192    , -0.0093377 ,  0.054738  ,\n",
       "       -0.049577  ,  0.016562  , -0.02128   , -0.0048423 , -0.031323  ,\n",
       "        0.064192  , -0.054712  ,  0.050789  , -0.019432  ,  0.036008  ,\n",
       "       -0.02158   ,  0.12594   ,  0.046742  , -0.072416  ,  0.029106  ,\n",
       "        0.13174   , -0.026134  , -0.020803  ,  0.083573  , -0.044436  ,\n",
       "       -0.015309  , -0.10827   ,  0.047964  , -0.033179  ,  0.01593   ,\n",
       "       -0.019974  ,  0.15257   ,  0.028162  , -0.011409  ,  0.0016001 ,\n",
       "        0.0079381 ,  0.082786  ,  0.045722  ,  0.032462  ,  0.001688  ,\n",
       "       -0.027112  ,  0.038471  , -0.00021096,  0.0079964 ,  0.0086245 ,\n",
       "       -0.054083  ,  0.058075  ,  0.01669   , -0.10596   ,  0.042212  ,\n",
       "        0.0010444 ,  0.040107  ,  0.0035127 , -0.0044197 , -0.077255  ,\n",
       "        0.13348   ,  0.028476  , -0.10541   ,  0.0093762 ,  0.0024769 ,\n",
       "       -0.098879  , -0.021902  , -0.0059303 ,  0.048143  , -0.0079448 ,\n",
       "        0.034722  , -0.013479  ,  0.0097968 ,  0.040053  ,  0.023351  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_w2v.get_vector('india')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5999a99",
   "metadata": {},
   "source": [
    "# 3. GloVe(Pre-Trained) - Glove_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "201b513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"C:\\\\Users\\\\raghav\\\\Desktop\\\\Files\\\\Jupyter_Notebook_Files\\\\NLP\\\\Word Embedding - Word2Vec & GloVe\\\\glove.6B.50d.txt\", encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a4d9fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Glove_dict = {}\n",
    "\n",
    "for i in f:\n",
    "    Glove_dict[i.split()[0]] = i.split()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435de6f",
   "metadata": {},
   "source": [
    "## Label Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c93ea92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = LabelEncoder()\n",
    "y = LE.fit_transform(df['Responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f2d2f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83eaa2",
   "metadata": {},
   "source": [
    "# Model1 = RNN with Word2Vec self trained - w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "34c781ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab062764",
   "metadata": {},
   "source": [
    "## Step1 : Using Tensorflow's Tokenizer, we are creating a text to sequences. The input to tokenizer is cleaned data that is in Word_Tokenized format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "012241b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tr= Tokenizer(num_words=319)\n",
    "Tr.fit_on_texts(cleaned_data)\n",
    "cleaned_data_seq = Tr.texts_to_sequences(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689167e9",
   "metadata": {},
   "source": [
    "## Step2: Create a numpy zero array (Tokenizers words length,Your word vector dimension). In our case it is (319,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ef7b5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_Word2vec_Self = np.zeros((len(Tr.word_index)+1,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55d04c",
   "metadata": {},
   "source": [
    "## Step3: Iterate over Tokenizer Word index items and get the word vector for each word and store it in numpy zero's matrix.\n",
    "\n",
    "### We use Tokenizer's to get every word\n",
    "### We use the word to get vector from word2vec model\n",
    "### We save the vector in numpy zeros array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6391d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word,i in Tr.word_index.items():\n",
    "    if w2v.wv.get_vector(word) is not None:\n",
    "        embedding_matrix_Word2vec_Self[i] = w2v.wv.get_vector(word)\n",
    "    else:\n",
    "        embedding_matrix_Word2vec_Self[i] = np.zeros((1,100))\n",
    "        print(f\"{word} not added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd30046c",
   "metadata": {},
   "source": [
    "## Step4: Pad the Sequences using the tokenizers text to sequence output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6b3b052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(cleaned_data_seq)\n",
    "y = target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e4d4d",
   "metadata": {},
   "source": [
    "## Input Dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f105b7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Tr.word_index)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac9a225",
   "metadata": {},
   "source": [
    "## Output Dimensions  - 100 vector dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fb8c655d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i) for i in cleaned_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "373bdf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59f14d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model1 = Sequential()\n",
    "Model1.add(Embedding(input_dim = len(Tr.word_index)+1,output_dim =100,weights = [embedding_matrix_Word2vec_Self],input_length=19))\n",
    "Model1.add(SimpleRNN(100))\n",
    "Model1.add(Dense(100,activation='relu'))\n",
    "Model1.add(Dense(50,activation='relu'))\n",
    "Model1.add(Dense(8,activation='softmax'))\n",
    "Model1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a54ec9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 16ms/step - loss: 2.0803 - accuracy: 0.1518\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.0394 - accuracy: 0.3874\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.9782 - accuracy: 0.4136\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.8736 - accuracy: 0.5864\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.7197 - accuracy: 0.5916\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4922 - accuracy: 0.7173\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2394 - accuracy: 0.7487\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9534 - accuracy: 0.8743\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7268 - accuracy: 0.9267\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5201 - accuracy: 0.9476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d83f9c3760>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model1.fit(X_train,y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e4d2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cee8e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2867351 , 0.15578812, 0.08798981, 0.1223792 , 0.21393375,\n",
       "       0.00864877, 0.09907303, 0.02545232], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aaef329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "value,classes_pred = tf.math.top_k(prediction, k=1, sorted=True, name=None)\n",
    "classes_actual = y_test.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48c6cf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.11      0.13         9\n",
      "           1       0.13      0.15      0.14        13\n",
      "           2       0.25      0.09      0.13        11\n",
      "           3       0.06      0.11      0.07         9\n",
      "           4       0.14      0.29      0.19        14\n",
      "           5       0.11      0.07      0.09        14\n",
      "           6       0.12      0.09      0.11        11\n",
      "           7       0.29      0.14      0.19        14\n",
      "\n",
      "    accuracy                           0.14        95\n",
      "   macro avg       0.16      0.13      0.13        95\n",
      "weighted avg       0.16      0.14      0.14        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes_actual,classes_pred.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de023c3",
   "metadata": {},
   "source": [
    "# Model2  = RNN with Word2vec Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d43001f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hi'],\n",
       " ['how', 'are', 'you'],\n",
       " ['hello', 'there'],\n",
       " ['hello'],\n",
       " ['whats', 'up'],\n",
       " ['hey'],\n",
       " ['yo'],\n",
       " ['listen'],\n",
       " ['please', 'help', 'me'],\n",
       " ['hi', 'there'],\n",
       " ['hello', 'bot'],\n",
       " ['whats', 'up', 'for', 'today'],\n",
       " ['hello', 'guys', 'i', 'need', 'a', 'help'],\n",
       " ['hey', 'there'],\n",
       " ['i', 'have', 'a', 'quick', 'question'],\n",
       " ['how', 'to', 'start'],\n",
       " ['online'],\n",
       " ['hey', 'ya'],\n",
       " ['talking', 'to', 'you', 'for', 'first', 'time'],\n",
       " ['anyone', 'there'],\n",
       " ['i', 'am', 'here', 'to', 'get', 'help'],\n",
       " ['someone', 'help', 'me', 'please'],\n",
       " ['ello'],\n",
       " ['wassuppp'],\n",
       " ['whats', 'happening', 'around', 'the', 'portal'],\n",
       " ['i', 'have', 'few', 'quick', 'questions'],\n",
       " ['i', 'need', 'a', 'help'],\n",
       " ['there'],\n",
       " ['what', 'is', 'your', 'name'],\n",
       " ['who', 'are', 'you'],\n",
       " ['how', 'do', 'they', 'call', 'you'],\n",
       " ['do', 'i', 'know', 'you'],\n",
       " ['who', 'is', 'there'],\n",
       " ['who', 'is', 'you'],\n",
       " ['your', 'name', 'please'],\n",
       " ['may', 'i', 'know', 'your', 'name'],\n",
       " ['speak', 'up'],\n",
       " ['are', 'you', 'a', 'human'],\n",
       " ['do', 'you', 'answer', 'questions'],\n",
       " ['who', 'is', 'learning', 'assistant'],\n",
       " ['who', 'is', 'supporting', 'assistant'],\n",
       " ['any', 'assistant'],\n",
       " ['whos', 'that', 'i', 'am', 'speaking', 'to'],\n",
       " ['may', 'i', 'know', 'who', 'you', 'are'],\n",
       " ['who', 'is', 'speaking'],\n",
       " ['are', 'you', 'a', 'bot', 'or', 'a', 'human'],\n",
       " ['who', 'am', 'i', 'speaking', 'to', 'a', 'bot', 'or', 'a', 'person'],\n",
       " ['how', 'do', 'i', 'call', 'you'],\n",
       " ['can', 'i', 'call', 'you', 'vla'],\n",
       " ['are', 'you', 'my', 'teacher'],\n",
       " ['they', 'call', 'you', 'with', 'what'],\n",
       " ['i', 'would', 'like', 'to', 'know', 'about', 'you'],\n",
       " ['you', 'are', 'what'],\n",
       " ['thank', 'you'],\n",
       " ['thanks'],\n",
       " ['cya'],\n",
       " ['see', 'you'],\n",
       " ['later'],\n",
       " ['see', 'you', 'later'],\n",
       " ['goodbye'],\n",
       " ['i', 'am', 'leaving'],\n",
       " ['have', 'a', 'good', 'day'],\n",
       " ['you', 'helped', 'me'],\n",
       " ['thanks', 'a', 'lot'],\n",
       " ['thanks', 'a', 'ton'],\n",
       " ['you', 'are', 'the', 'best'],\n",
       " ['great', 'help'],\n",
       " ['too', 'good'],\n",
       " ['you', 'are', 'a', 'good', 'learning', 'buddy'],\n",
       " ['ok', 'i', 'am', 'good'],\n",
       " ['alright', 'i', \"'m\", 'good'],\n",
       " ['thanks', 'for', 'help'],\n",
       " ['doubt', 'cleared'],\n",
       " ['exit'],\n",
       " ['quit', 'cleared'],\n",
       " ['that', 'â€™', 's', 'a', 'wrap'],\n",
       " ['bye', 'bye'],\n",
       " ['ty'],\n",
       " ['i', 'think', 'you', 'cleared', 'my', 'doubt'],\n",
       " ['you', 'can', 'answer', 'well'],\n",
       " ['you',\n",
       "  'are',\n",
       "  'a',\n",
       "  'good',\n",
       "  'replacement',\n",
       "  'for',\n",
       "  'humans',\n",
       "  'to',\n",
       "  'clarify',\n",
       "  'doubts'],\n",
       " ['i',\n",
       "  'think',\n",
       "  'i',\n",
       "  'am',\n",
       "  'good',\n",
       "  'with',\n",
       "  'your',\n",
       "  'answer',\n",
       "  'it',\n",
       "  'seems',\n",
       "  'to',\n",
       "  'be',\n",
       "  'clear',\n",
       "  'and',\n",
       "  'i',\n",
       "  'can',\n",
       "  'do',\n",
       "  'this',\n",
       "  'now'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'svm'],\n",
       " ['explain', 'me', 'how', 'machine', 'learning', 'works'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'naive', 'bayes'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'logistic', 'regression'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'ensemble', 'techb=niques'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'knn'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'knn', 'imputer'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'cross', 'validation'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'boosting'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'random', 'forest'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'ada', 'boosting'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'gradient', 'boosting'],\n",
       " ['machine', 'learning'],\n",
       " ['ml'],\n",
       " ['sl'],\n",
       " ['supervised', 'learning'],\n",
       " ['knn'],\n",
       " ['logistic', 'regression'],\n",
       " ['regression'],\n",
       " ['classification'],\n",
       " ['naive', 'bayes'],\n",
       " ['nb'],\n",
       " ['ensemble', 'techniques'],\n",
       " ['bagging'],\n",
       " ['boosting'],\n",
       " ['ada', 'boosting'],\n",
       " ['ada'],\n",
       " ['gradient', 'boosting'],\n",
       " ['hyper', 'parameters'],\n",
       " ['what', 'is', 'deep', 'learning'],\n",
       " ['unable', 'to', 'understand', 'deep', 'learning'],\n",
       " ['explain', 'me', 'how', 'deep', 'learning', 'works'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'deep', 'learning'],\n",
       " ['not', 'able', 'to', 'understand', 'neural', 'nets'],\n",
       " ['very', 'diffult', 'to', 'understand', 'neural', 'nets'],\n",
       " ['unable', 'to', 'understand', 'neural', 'nets'],\n",
       " ['ann'],\n",
       " ['artificial', 'intelligence'],\n",
       " ['artificial', 'neural', 'networks'],\n",
       " ['weights'],\n",
       " ['activation', 'function'],\n",
       " ['hidden', 'layers'],\n",
       " ['softmax'],\n",
       " ['sigmoid'],\n",
       " ['relu'],\n",
       " ['otimizer'],\n",
       " ['forward', 'propagation'],\n",
       " ['backward', 'propagation'],\n",
       " ['epochs'],\n",
       " ['epoch'],\n",
       " ['what', 'is', 'an', 'epoch'],\n",
       " ['adam'],\n",
       " ['sgd'],\n",
       " ['what', 'is', 'ai'],\n",
       " ['can', 'you', 'think'],\n",
       " ['how', 'does', 'machines', 'think'],\n",
       " ['perceptron'],\n",
       " ['what', 'is', 'early', 'stopping'],\n",
       " ['olympus'],\n",
       " ['explain', 'me', 'how', 'olympus', 'works'],\n",
       " ['i', 'am', 'not', 'able', 'to', 'understand', 'olympus'],\n",
       " ['olympus', 'window', 'not', 'working'],\n",
       " ['no', 'access', 'to', 'olympus'],\n",
       " ['unable', 'to', 'see', 'link', 'in', 'olympus'],\n",
       " ['no', 'link', 'visible', 'on', 'olympus'],\n",
       " ['whom', 'to', 'contact', 'for', 'olympus'],\n",
       " ['lot', 'of', 'problem', 'with', 'olympus'],\n",
       " ['olypus', 'is', 'not', 'a', 'good', 'tool'],\n",
       " ['lot', 'of', 'problems', 'with', 'olympus'],\n",
       " ['how', 'to', 'use', 'olympus'],\n",
       " ['teach', 'me', 'olympus'],\n",
       " ['portal', 'not', 'working'],\n",
       " ['give', 'me', 'portal', 'link'],\n",
       " ['olympus', 'portal'],\n",
       " ['pg', 'portal'],\n",
       " ['course', 'portal'],\n",
       " ['poc', 'for', 'olympus', 'portal'],\n",
       " ['help', 'me', 'on', 'olympus', 'portal'],\n",
       " ['tell', 'me', 'how', 'this', 'pg', 'works'],\n",
       " ['may', 'i', 'have', 'the', 'wiki', 'page', 'for', 'this', 'pg', 'course'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'an',\n",
       "  'ongoing',\n",
       "  'problem',\n",
       "  'with',\n",
       "  'the',\n",
       "  'site',\n",
       "  'is',\n",
       "  'it',\n",
       "  'down'],\n",
       " ['do', 'you', 'have', 'wikipedia', 'for', 'this', 'pg'],\n",
       " ['which', 'site', 'helps', 'in', 'displaying', 'the', 'course'],\n",
       " ['do', 'i', 'need', 'to', 'login', 'to', 'use', 'this', 'course'],\n",
       " ['is', 'there', 'any', 'portal', 'to', 'display', 'all', 'the', 'courses'],\n",
       " ['where', 'do', 'i', 'see', 'my', 'rank'],\n",
       " ['where', 'shall', 'i', 'see', 'my', 'marks'],\n",
       " ['what', 'the', 'hell', 'are', 'you', 'talking', 'about'],\n",
       " ['bloody', 'stupid', 'bot'],\n",
       " ['do', 'you', 'think', 'you', 'are', 'very', 'smart'],\n",
       " ['screw', 'you'],\n",
       " ['i', 'hate', 'you'],\n",
       " ['you', 'are', 'stupid'],\n",
       " ['jerk'],\n",
       " ['you', 'are', 'a', 'joke'],\n",
       " ['useless', 'piece', 'of', 'shit'],\n",
       " ['get', 'lost'],\n",
       " ['you', 'stupid'],\n",
       " ['dont', 'talk', 'like', 'an', 'idiot'],\n",
       " ['do', 'you', 'have', 'sense'],\n",
       " ['senseless', 'creature'],\n",
       " ['shut', 'your', 'mouth'],\n",
       " ['dont', 'speak', 'like', 'a', 'dummy'],\n",
       " ['you', 'stupid', 'dummy'],\n",
       " ['shut', 'up'],\n",
       " ['you', 'deserve', 'bad', 'words', 'and', 'bad', 'shit', 'only'],\n",
       " ['shut', 'your', 'useless', 'responses'],\n",
       " ['you', 'are', 'just', 'a', 'junk', 'that', 'has', 'no', 'value'],\n",
       " ['bloody'],\n",
       " ['stupid'],\n",
       " ['shit'],\n",
       " ['dum'],\n",
       " ['i', 'said', 'shutttt', 'upppp'],\n",
       " ['get', 'out', 'of', 'my', 'way'],\n",
       " ['you', 'are', 'a', 'complete', 'mess'],\n",
       " ['messy', 'creature'],\n",
       " ['my', 'problem', 'is', 'not', 'solved'],\n",
       " ['you', 'did', 'not', 'help', 'me'],\n",
       " ['not', 'a', 'good', 'solution'],\n",
       " ['bad', 'solution'],\n",
       " ['not', 'good', 'solution'],\n",
       " ['no', 'help'],\n",
       " ['wasted', 'my', 'time'],\n",
       " ['useless', 'bot'],\n",
       " ['create', 'a', 'ticket'],\n",
       " ['i', 'dont', 'see', 'a', 'solution'],\n",
       " ['where', 'is', 'the', 'solution'],\n",
       " ['connect', 'me', 'to', 'a', 'human'],\n",
       " ['want', 'to', 'talk', 'to', 'a', 'person'],\n",
       " ['this', 'is', 'not', 'an', 'answer'],\n",
       " ['its', 'not', 'a', 'solution'],\n",
       " ['this', 'is', 'not', 'a', 'solution'],\n",
       " ['please', 'push', 'it', 'to', 'a', 'human'],\n",
       " ['i', 'do', 'not', 'want', 'to', 'talk', 'to', 'a', 'bot'],\n",
       " ['do', 'not', 'connect', 'to', 'a', 'bot'],\n",
       " ['someone', 'please', 'answer', 'my', 'question'],\n",
       " ['can',\n",
       "  'you',\n",
       "  'please',\n",
       "  'connect',\n",
       "  'me',\n",
       "  'to',\n",
       "  'someone',\n",
       "  'who',\n",
       "  'can',\n",
       "  'talk'],\n",
       " ['i', 'would', 'need', 'a', 'better', 'help'],\n",
       " ['i', 'need', 'my', 'query', 'to', 'be', 'manually', 'handled'],\n",
       " ['i', 'would', 'need', 'a', 'real', 'assistant'],\n",
       " ['this', 'aint', 'helping', 'me', 'get', 'to', 'the', 'solution'],\n",
       " ['can', 'i', 'get', 'a', 'better', 'solution'],\n",
       " ['can', 'i', 'get', 'a', 'better', 'answer'],\n",
       " ['i',\n",
       "  'can',\n",
       "  'not',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'a',\n",
       "  'bot',\n",
       "  'i',\n",
       "  'need',\n",
       "  'human',\n",
       "  'intervention'],\n",
       " ['i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'intrested',\n",
       "  'in',\n",
       "  'talking',\n",
       "  'to',\n",
       "  'an',\n",
       "  'automated',\n",
       "  'computer'],\n",
       " ['somebody', 'please', 'help', 'me'],\n",
       " ['good', 'morning'],\n",
       " ['good', 'afternoon'],\n",
       " ['good', 'evening'],\n",
       " ['someone', 'there'],\n",
       " ['your', 'are'],\n",
       " ['you', 'are'],\n",
       " ['are', 'you', 'their', 'assistant'],\n",
       " ['what', 'are', 'you'],\n",
       " ['whats', 'your', 'name'],\n",
       " ['how', 'am', 'i', 'supposed', 'to', 'call', 'you'],\n",
       " ['my', 'doubt', 'is', 'cleared'],\n",
       " ['my', 'issue', 'is', 'rectified'],\n",
       " ['im', 'good'],\n",
       " ['its', 'clear'],\n",
       " ['all', 'clear'],\n",
       " ['perfect', 'this', 'is', 'what', 'i', 'need'],\n",
       " ['this', 'clears', 'my', 'doubt'],\n",
       " ['what', 'is', 'svm', 'that', 'is', 'the', 'support', 'vector', 'machines'],\n",
       " ['what', 'is', 'ml'],\n",
       " ['what', 'is', 'machine', 'learning'],\n",
       " ['its', 'about', 'machine', 'learning'],\n",
       " ['its', 'about', 'ml'],\n",
       " ['ml', 'technique', 'doubts'],\n",
       " ['i', 'have', 'doubts', 'on', 'ml'],\n",
       " ['i', 'have', 'doubts', 'on', 'ml', 'techniques'],\n",
       " ['i', 'have', 'doubt', 'on', 'algorithms'],\n",
       " ['ml', 'algorithms', 'doubt'],\n",
       " ['can', 'you', 'help', 'me', 'understand', 'the', 'ml', 'algorithms'],\n",
       " ['i', 'just', 'cant', 'understand', 'the', 'ann'],\n",
       " ['what', 'is', 'ann'],\n",
       " ['ann'],\n",
       " ['what', 'does', 'ann', 'do'],\n",
       " ['advantages', 'of', 'ann'],\n",
       " ['is', 'ann', 'efficient'],\n",
       " ['what', 'is', 'universal', 'approximation'],\n",
       " ['neural', 'networks'],\n",
       " ['what', 'is', 'nn'],\n",
       " ['i', 'would', 'like', 'some', 'support', 'on', 'nn'],\n",
       " ['i', 'would', 'like', 'some', 'support', 'on', 'ann'],\n",
       " ['somebody', 'please', 'help', 'me', 'understand', 'ann'],\n",
       " ['someone', 'can', 'explain', 'how', 'the', 'portal', 'works'],\n",
       " ['where', 'is', 'the', 'aiml', 'portal'],\n",
       " ['where', 'do', 'i', 'see', 'the', 'course', 'materials'],\n",
       " ['where',\n",
       "  'do',\n",
       "  'i',\n",
       "  'see',\n",
       "  'the',\n",
       "  'recordings',\n",
       "  'of',\n",
       "  'the',\n",
       "  'mentor',\n",
       "  'session'],\n",
       " ['what', 'are', 'the', 'features', 'of', 'the', 'olympus', 'portal'],\n",
       " ['how', 'do', 'i', 'access', 'the', 'portal', 'to', 'learn'],\n",
       " ['shut', 'your', 'answers', 'right', 'now'],\n",
       " ['shitty', 'bot'],\n",
       " ['just', 'cant', 'stand', 'your', 'stupid', 'responses'],\n",
       " ['get', 'lost', 'you', 'idiotic', 'bot'],\n",
       " ['can', 'someone', 'please', 'help', 'me', 'with', 'better', 'answer'],\n",
       " ['is', 'there', 'a', 'human', 'to', 'clear', 'my', 'doubts'],\n",
       " ['please', 'send', 'in', 'some', 'human', 'to', 'clear', 'my', 'doubts'],\n",
       " ['please', 'get', 'some', 'live', 'person', 'to', 'clear', 'my', 'doubts'],\n",
       " ['your',\n",
       "  'answers',\n",
       "  'are',\n",
       "  'not',\n",
       "  'clear',\n",
       "  'and',\n",
       "  'correct',\n",
       "  'i',\n",
       "  'need',\n",
       "  'help'],\n",
       " ['i', 'need', 'better', 'answers', 'to', 'my', 'questions'],\n",
       " ['these', 'are', 'not', 'clear', 'answers'],\n",
       " ['you',\n",
       "  'please',\n",
       "  'connect',\n",
       "  'this',\n",
       "  'conversation',\n",
       "  'to',\n",
       "  'a',\n",
       "  'live',\n",
       "  'human',\n",
       "  'conversation']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4578079",
   "metadata": {},
   "source": [
    "## Step1: Tokenizer to get text sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7f41fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TK2 = Tokenizer()\n",
    "TK2.fit_on_texts(cleaned_data)\n",
    "cleaned_data_Seq = TK2.texts_to_sequences(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "087c5bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x2d7dbeede50>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c28fd8",
   "metadata": {},
   "source": [
    "## Step2: Create a numpy zeros array ok tokenizer word index length+1 and embedding dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5979c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_w2v_embedding = np.zeros((len(TK2.word_index)+1,300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8d438",
   "metadata": {},
   "source": [
    "## Step3: Iterate over the tokenizer index items that gives word and word index, update the Numpy zeros using array index with vectors for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8874141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term svm is not available in the pretrained model.\n",
      "The term wassuppp is not available in the pretrained model.\n",
      "The term techb=niques is not available in the pretrained model.\n",
      "The term imputer is not available in the pretrained model.\n",
      "The term diffult is not available in the pretrained model.\n",
      "The term relu is not available in the pretrained model.\n",
      "The term otimizer is not available in the pretrained model.\n",
      "The term olypus is not available in the pretrained model.\n",
      "The term shutttt is not available in the pretrained model.\n",
      "The term upppp is not available in the pretrained model.\n",
      "The term aiml is not available in the pretrained model.\n"
     ]
    }
   ],
   "source": [
    "for word,i in TK2.word_index.items():\n",
    "    try:\n",
    "        pretrained_w2v_embedding[i] = pretrained_w2v.get_vector(word)\n",
    "    except:\n",
    "        print(f\"The term {word} is not available in the pretrained model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903d2c8",
   "metadata": {},
   "source": [
    "## Step4: Find the max length of the cleaned data. Later pad the sequences using Tokenizer's Text to sequence content and perform train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "50da3294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i) for i in cleaned_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c4874575",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(cleaned_data_Seq,maxlen=19)\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bb29c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50beb2ed",
   "metadata": {},
   "source": [
    "## Step5: Create an Embedding layer using the below mentioned:\n",
    "### Input Dimensions: Tokenizer word index length + 1\n",
    "### Output Dimensions: Embedding dimension\n",
    "### Weights : The numpy zeros array that was filled with vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db0077f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model2 = Sequential()\n",
    "Model2.add(Embedding(input_dim=len(TK2.word_index)+1,output_dim=300,weights=[pretrained_w2v_embedding]))\n",
    "Model2.add(SimpleRNN(100))\n",
    "Model2.add(Dense(150,activation='relu'))\n",
    "Model2.add(Dense(75,activation='relu'))\n",
    "Model2.add(Dense(30,activation='relu'))\n",
    "Model2.add(Dense(8,activation='softmax'))\n",
    "Model2.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b899e01a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 45ms/step - loss: 2.0723 - accuracy: 0.1518 - val_loss: 2.0326 - val_accuracy: 0.2316\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.9382 - accuracy: 0.3403 - val_loss: 1.9552 - val_accuracy: 0.2737\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.7761 - accuracy: 0.4869 - val_loss: 1.8492 - val_accuracy: 0.3368\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.5563 - accuracy: 0.5969 - val_loss: 1.7267 - val_accuracy: 0.4105\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.2942 - accuracy: 0.6754 - val_loss: 1.5444 - val_accuracy: 0.4632\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.0024 - accuracy: 0.8168 - val_loss: 1.4237 - val_accuracy: 0.5368\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7151 - accuracy: 0.8691 - val_loss: 1.2804 - val_accuracy: 0.5684\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4855 - accuracy: 0.9319 - val_loss: 1.4552 - val_accuracy: 0.5474\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3240 - accuracy: 0.9686 - val_loss: 1.2721 - val_accuracy: 0.6211\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.1536 - accuracy: 1.0000 - val_loss: 1.2187 - val_accuracy: 0.6421\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 1.3220 - val_accuracy: 0.6526\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 1.4662 - val_accuracy: 0.6211\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.5196 - val_accuracy: 0.6105\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.5187 - val_accuracy: 0.6421\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5249 - val_accuracy: 0.6421\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.5587 - val_accuracy: 0.6421\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5955 - val_accuracy: 0.6421\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.6178 - val_accuracy: 0.6421\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.6332 - val_accuracy: 0.6421\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.6475 - val_accuracy: 0.6421\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6609 - val_accuracy: 0.6421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d84c552340>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES = EarlyStopping(monitor='val_accuracy',min_delta=0.01,patience=10)\n",
    "Model2.fit(X_train,y_train,epochs=100,callbacks=[ES],validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "358c403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_2 = Model2.predict(X_test)\n",
    "value,classes_pred = tf.math.top_k(prediction_2,k=1, sorted=True, name=None)\n",
    "classes_actual = y_test.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a469eb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69        12\n",
      "           1       0.55      0.67      0.60         9\n",
      "           2       0.62      0.42      0.50        12\n",
      "           3       0.54      0.93      0.68        14\n",
      "           4       0.86      0.46      0.60        13\n",
      "           5       0.79      1.00      0.88        11\n",
      "           6       0.71      0.45      0.56        11\n",
      "           7       0.60      0.46      0.52        13\n",
      "\n",
      "    accuracy                           0.64        95\n",
      "   macro avg       0.66      0.64      0.63        95\n",
      "weighted avg       0.66      0.64      0.63        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes_actual,classes_pred.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e19bd9a",
   "metadata": {},
   "source": [
    "# Model 3: RNN with GloVe(Pre-Trained) - Glove_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f5e4ba",
   "metadata": {},
   "source": [
    "## Step1: Use Tokenizer to create text sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "60ce1b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk3 = Tokenizer()\n",
    "tk3.fit_on_texts(cleaned_data)\n",
    "data_seq = tk3.texts_to_sequences(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bf1767",
   "metadata": {},
   "source": [
    "## Step2: Create numpy zeros array using tokenizer word index length and 50 dimensions. Then, iterate over the tokenizer's word index items to get word and their index, using this update the numpy zeros array with the Glove vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7241a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaned_data_Glove = np.zeros((len(tk3.word_index.items())+1,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "53108e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word knn is not available in Glove\n",
      "The word wassuppp is not available in Glove\n",
      "The word techb=niques is not available in Glove\n",
      "The word imputer is not available in Glove\n",
      "The word diffult is not available in Glove\n",
      "The word softmax is not available in Glove\n",
      "The word relu is not available in Glove\n",
      "The word otimizer is not available in Glove\n",
      "The word olypus is not available in Glove\n",
      "The word shutttt is not available in Glove\n",
      "The word upppp is not available in Glove\n",
      "The word intrested is not available in Glove\n",
      "The word aiml is not available in Glove\n"
     ]
    }
   ],
   "source": [
    "for word,i in tk3.word_index.items():\n",
    "    try:\n",
    "        Cleaned_data_Glove[i] = Glove_dict[word]\n",
    "    except:\n",
    "        print(f\"The word {word} is not available in Glove\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf97873",
   "metadata": {},
   "source": [
    "## Step3: Find the sequences max length, use this to create padded sequences and generate train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "487c413e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i) for i in cleaned_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "29a071a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(data_seq,maxlen=19)\n",
    "y = target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a1403fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ES=EarlyStopping(monitor='val_accuracy',min_delta=0.001,patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5059b3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 44ms/step - loss: 2.0525 - accuracy: 0.2408 - val_loss: 1.9870 - val_accuracy: 0.2211\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 1.6379 - accuracy: 0.4974 - val_loss: 1.7994 - val_accuracy: 0.3895\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.3588 - accuracy: 0.6073 - val_loss: 1.6590 - val_accuracy: 0.4105\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.1291 - accuracy: 0.7225 - val_loss: 1.5263 - val_accuracy: 0.4737\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9450 - accuracy: 0.8377 - val_loss: 1.4459 - val_accuracy: 0.5474\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7811 - accuracy: 0.8639 - val_loss: 1.4027 - val_accuracy: 0.5368\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6425 - accuracy: 0.8848 - val_loss: 1.3632 - val_accuracy: 0.5474\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5326 - accuracy: 0.9215 - val_loss: 1.3491 - val_accuracy: 0.5158\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4367 - accuracy: 0.9319 - val_loss: 1.3228 - val_accuracy: 0.5368\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3491 - accuracy: 0.9529 - val_loss: 1.3335 - val_accuracy: 0.5579\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.2769 - accuracy: 0.9634 - val_loss: 1.3208 - val_accuracy: 0.5579\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2259 - accuracy: 0.9895 - val_loss: 1.3187 - val_accuracy: 0.5789\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1893 - accuracy: 0.9895 - val_loss: 1.3176 - val_accuracy: 0.5895\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1503 - accuracy: 0.9948 - val_loss: 1.3239 - val_accuracy: 0.6105\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1253 - accuracy: 0.9948 - val_loss: 1.3351 - val_accuracy: 0.6105\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 1.3465 - val_accuracy: 0.6316\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 1.3481 - val_accuracy: 0.6316\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0752 - accuracy: 1.0000 - val_loss: 1.3432 - val_accuracy: 0.6316\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 1.3571 - val_accuracy: 0.6316\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 1.3705 - val_accuracy: 0.6316\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 1.3810 - val_accuracy: 0.6316\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 1.3872 - val_accuracy: 0.6316\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 1.3871 - val_accuracy: 0.6211\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 1.4000 - val_accuracy: 0.6316\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 1.4093 - val_accuracy: 0.6316\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 1.4135 - val_accuracy: 0.6211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d852aade20>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model3 = Sequential()\n",
    "Model3.add(Embedding(input_dim=len(tk3.word_index)+1, output_dim=50,input_length=19,weights=[Cleaned_data_Glove]))\n",
    "Model3.add(SimpleRNN(100))\n",
    "Model3.add(Dense(100,activation='tanh'))\n",
    "Model3.add(Dense(50,activation='tanh'))\n",
    "Model3.add(Dense(8,activation='softmax'))\n",
    "Model3.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "Model3.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d59b6b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tk3.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3a3aedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_3 = Model3.predict(X_test)\n",
    "value,classes_pred = tf.math.top_k(prediction_3,k=1, sorted=True, name=None)\n",
    "classes_actual = y_test.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9d3288d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56         9\n",
      "           1       0.65      0.85      0.73        13\n",
      "           2       0.43      0.55      0.48        11\n",
      "           3       0.54      0.78      0.64         9\n",
      "           4       0.75      0.64      0.69        14\n",
      "           5       1.00      0.64      0.78        14\n",
      "           6       0.50      0.36      0.42        11\n",
      "           7       0.62      0.57      0.59        14\n",
      "\n",
      "    accuracy                           0.62        95\n",
      "   macro avg       0.63      0.62      0.61        95\n",
      "weighted avg       0.65      0.62      0.62        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes_actual,classes_pred.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92344865",
   "metadata": {},
   "source": [
    "# Model4 : LSTM with Word2vec Self trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "45d1e43d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 2s 101ms/step - loss: 2.0792 - accuracy: 0.1361 - val_loss: 2.0761 - val_accuracy: 0.2105\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 2.0721 - accuracy: 0.2094 - val_loss: 2.0678 - val_accuracy: 0.3053\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.0573 - accuracy: 0.3665 - val_loss: 2.0527 - val_accuracy: 0.2842\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.0273 - accuracy: 0.3822 - val_loss: 2.0246 - val_accuracy: 0.3368\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.9694 - accuracy: 0.4136 - val_loss: 1.9679 - val_accuracy: 0.3053\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 1.8638 - accuracy: 0.3822 - val_loss: 1.8769 - val_accuracy: 0.3053\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.6612 - accuracy: 0.5288 - val_loss: 1.7650 - val_accuracy: 0.3474\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 1.4736 - accuracy: 0.4555 - val_loss: 1.7571 - val_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.3015 - accuracy: 0.6073 - val_loss: 1.5587 - val_accuracy: 0.5158\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 1.1110 - accuracy: 0.6021 - val_loss: 1.3767 - val_accuracy: 0.5474\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.8833 - accuracy: 0.7487 - val_loss: 1.3044 - val_accuracy: 0.5789\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.6881 - accuracy: 0.8115 - val_loss: 1.2708 - val_accuracy: 0.6421\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.5684 - accuracy: 0.8534 - val_loss: 1.3294 - val_accuracy: 0.5895\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.4377 - accuracy: 0.9162 - val_loss: 1.2920 - val_accuracy: 0.6842\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.3529 - accuracy: 0.9215 - val_loss: 1.3732 - val_accuracy: 0.6421\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.2882 - accuracy: 0.9476 - val_loss: 1.4934 - val_accuracy: 0.6105\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1977 - accuracy: 0.9791 - val_loss: 1.5781 - val_accuracy: 0.6105\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1536 - accuracy: 0.9738 - val_loss: 1.6269 - val_accuracy: 0.6526\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1107 - accuracy: 0.9895 - val_loss: 1.7683 - val_accuracy: 0.6526\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0940 - accuracy: 0.9948 - val_loss: 1.8090 - val_accuracy: 0.6105\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0826 - accuracy: 0.9843 - val_loss: 1.7767 - val_accuracy: 0.6632\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0792 - accuracy: 0.9948 - val_loss: 1.9224 - val_accuracy: 0.6316\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 2.1039 - val_accuracy: 0.5895\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 2.0749 - val_accuracy: 0.6421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d8530b8280>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model4 = Sequential()\n",
    "Model4.add(Embedding(input_dim = len(Tr.word_index)+1,output_dim =100,weights = [embedding_matrix_Word2vec_Self],input_length=19))\n",
    "Model4.add(LSTM(100))\n",
    "Model4.add(Dense(100,activation='relu'))\n",
    "Model4.add(Dense(50,activation='relu'))\n",
    "Model4.add(Dense(8,activation='softmax'))\n",
    "Model4.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "ES = EarlyStopping(monitor='val_accuracy',min_delta=0.001,patience=10)\n",
    "Model4.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6ec1b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_4 = Model4.predict(X_test)\n",
    "value,classes_pred = tf.math.top_k(prediction_4,k=1, sorted=True, name=None)\n",
    "classes_actual = y_test.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "60156c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.75      0.51        12\n",
      "           1       0.75      0.33      0.46         9\n",
      "           2       0.67      0.50      0.57        12\n",
      "           3       0.75      0.86      0.80        14\n",
      "           4       1.00      0.46      0.63        13\n",
      "           5       0.92      1.00      0.96        11\n",
      "           6       0.54      0.64      0.58        11\n",
      "           7       0.58      0.54      0.56        13\n",
      "\n",
      "    accuracy                           0.64        95\n",
      "   macro avg       0.70      0.63      0.63        95\n",
      "weighted avg       0.70      0.64      0.64        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes_actual,classes_pred.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a1d9b7",
   "metadata": {},
   "source": [
    "# Model5 : LSTM with Word2vec Pretrained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "601700af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 2s 103ms/step - loss: 2.0790 - accuracy: 0.1466 - val_loss: 2.0760 - val_accuracy: 0.2105\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 2.0712 - accuracy: 0.2251 - val_loss: 2.0685 - val_accuracy: 0.1789\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 2.0546 - accuracy: 0.2880 - val_loss: 2.0537 - val_accuracy: 0.3053\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 2.0239 - accuracy: 0.4241 - val_loss: 2.0241 - val_accuracy: 0.3053\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 1.9590 - accuracy: 0.3665 - val_loss: 1.9667 - val_accuracy: 0.3158\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 1.8302 - accuracy: 0.5131 - val_loss: 1.8832 - val_accuracy: 0.2737\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.6472 - accuracy: 0.4084 - val_loss: 1.7192 - val_accuracy: 0.4632\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.3780 - accuracy: 0.5916 - val_loss: 1.5598 - val_accuracy: 0.3368\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.1240 - accuracy: 0.7068 - val_loss: 1.3918 - val_accuracy: 0.5684\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.8455 - accuracy: 0.7696 - val_loss: 1.3060 - val_accuracy: 0.5895\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.6321 - accuracy: 0.8953 - val_loss: 1.2526 - val_accuracy: 0.5895\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.4417 - accuracy: 0.9215 - val_loss: 1.1923 - val_accuracy: 0.6421\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2796 - accuracy: 0.9476 - val_loss: 1.2413 - val_accuracy: 0.5895\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.2070 - accuracy: 0.9738 - val_loss: 1.4234 - val_accuracy: 0.5684\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1486 - accuracy: 0.9791 - val_loss: 1.2225 - val_accuracy: 0.6211\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1089 - accuracy: 0.9895 - val_loss: 1.2676 - val_accuracy: 0.6211\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0840 - accuracy: 0.9895 - val_loss: 1.4721 - val_accuracy: 0.6105\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 1.2856 - val_accuracy: 0.6105\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 1.3867 - val_accuracy: 0.6105\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.4192 - val_accuracy: 0.5789\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.4066 - val_accuracy: 0.6105\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.4723 - val_accuracy: 0.6105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d854b77c70>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model5 = Sequential()\n",
    "Model5.add(Embedding(input_dim = len(Tr.word_index)+1,output_dim =100,weights = [embedding_matrix_Word2vec_Self],input_length=19))\n",
    "Model5.add(LSTM(100))\n",
    "Model5.add(Dense(100,activation='relu'))\n",
    "Model5.add(Dense(50,activation='relu'))\n",
    "Model5.add(Dense(8,activation='softmax'))\n",
    "Model5.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "ES = EarlyStopping(monitor='val_accuracy',min_delta=0.001,patience=10)\n",
    "Model5.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "977ee846",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_5 = Model5.predict(X_test)\n",
    "value,classes_pred = tf.math.top_k(prediction_5,k=1, sorted=True, name=None)\n",
    "classes_actual = y_test.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "509fe72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50        12\n",
      "           1       0.71      0.56      0.63         9\n",
      "           2       0.32      0.58      0.41        12\n",
      "           3       0.68      0.93      0.79        14\n",
      "           4       1.00      0.46      0.63        13\n",
      "           5       0.85      1.00      0.92        11\n",
      "           6       1.00      0.27      0.43        11\n",
      "           7       0.54      0.54      0.54        13\n",
      "\n",
      "    accuracy                           0.61        95\n",
      "   macro avg       0.70      0.61      0.60        95\n",
      "weighted avg       0.70      0.61      0.61        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes_actual,classes_pred.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d2faf0",
   "metadata": {},
   "source": [
    "# Model6 : LSTM with GloVe Pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6fbdced9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 2s 106ms/step - loss: 2.0784 - accuracy: 0.1257 - val_loss: 2.0777 - val_accuracy: 0.1684\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.0680 - accuracy: 0.2094 - val_loss: 2.0712 - val_accuracy: 0.1474\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 2.0472 - accuracy: 0.1414 - val_loss: 2.0629 - val_accuracy: 0.1474\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.0050 - accuracy: 0.1780 - val_loss: 2.0368 - val_accuracy: 0.1684\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.9339 - accuracy: 0.2147 - val_loss: 1.9669 - val_accuracy: 0.2947\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.8292 - accuracy: 0.2880 - val_loss: 1.8714 - val_accuracy: 0.4316\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.6818 - accuracy: 0.3560 - val_loss: 1.7719 - val_accuracy: 0.3474\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.5359 - accuracy: 0.3979 - val_loss: 1.6560 - val_accuracy: 0.4526\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.3086 - accuracy: 0.6230 - val_loss: 1.6316 - val_accuracy: 0.3895\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.0870 - accuracy: 0.7016 - val_loss: 1.5764 - val_accuracy: 0.4842\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.8941 - accuracy: 0.7435 - val_loss: 1.5515 - val_accuracy: 0.5053\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.7488 - accuracy: 0.8325 - val_loss: 1.4003 - val_accuracy: 0.5684\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.5573 - accuracy: 0.8796 - val_loss: 1.4404 - val_accuracy: 0.5789\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.4911 - accuracy: 0.8429 - val_loss: 1.5825 - val_accuracy: 0.4737\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.4426 - accuracy: 0.8901 - val_loss: 1.2723 - val_accuracy: 0.6421\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.3339 - accuracy: 0.9529 - val_loss: 1.4773 - val_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.2122 - accuracy: 0.9738 - val_loss: 1.6406 - val_accuracy: 0.6105\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1692 - accuracy: 0.9791 - val_loss: 1.5731 - val_accuracy: 0.5895\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.1174 - accuracy: 0.9895 - val_loss: 1.7088 - val_accuracy: 0.6211\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0853 - accuracy: 0.9895 - val_loss: 1.6778 - val_accuracy: 0.6105\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 1.6258 - val_accuracy: 0.6211\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 1.8412 - val_accuracy: 0.6421\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 1.8530 - val_accuracy: 0.6105\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0398 - accuracy: 0.9948 - val_loss: 2.0117 - val_accuracy: 0.6316\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 1.8355 - val_accuracy: 0.6421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d852d639d0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model6 = Sequential()\n",
    "Model6.add(Embedding(input_dim = len(Tr.word_index)+1,output_dim =100,weights = [embedding_matrix_Word2vec_Self],input_length=19))\n",
    "Model6.add(LSTM(100))\n",
    "Model6.add(Dense(100,activation='relu'))\n",
    "Model6.add(Dense(50,activation='relu'))\n",
    "Model6.add(Dense(8,activation='softmax'))\n",
    "Model6.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "ES = EarlyStopping(monitor='val_accuracy',min_delta=0.001,patience=10)\n",
    "Model6.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "805c5eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_6 = Model6.predict(X_test)\n",
    "value,classes_pred = tf.math.top_k(prediction_6,k=1, sorted=True, name=None)\n",
    "classes_actual = y_test.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "039d81e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.44      0.44         9\n",
      "           1       0.60      0.46      0.52        13\n",
      "           2       0.35      0.64      0.45        11\n",
      "           3       1.00      0.89      0.94         9\n",
      "           4       0.76      0.93      0.84        14\n",
      "           5       0.92      0.79      0.85        14\n",
      "           6       0.40      0.18      0.25        11\n",
      "           7       0.71      0.71      0.71        14\n",
      "\n",
      "    accuracy                           0.64        95\n",
      "   macro avg       0.65      0.63      0.63        95\n",
      "weighted avg       0.66      0.64      0.64        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes_actual,classes_pred.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1822c38",
   "metadata": {},
   "source": [
    "# Model7 : GRU with Word2Vec Self trained embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "741bd307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 2s 95ms/step - loss: 2.0780 - accuracy: 0.1780 - val_loss: 2.0740 - val_accuracy: 0.2105\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 2.0624 - accuracy: 0.3298 - val_loss: 2.0605 - val_accuracy: 0.3684\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 2.0311 - accuracy: 0.4136 - val_loss: 2.0334 - val_accuracy: 0.3579\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.9641 - accuracy: 0.4974 - val_loss: 1.9799 - val_accuracy: 0.4000\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.8386 - accuracy: 0.4869 - val_loss: 1.8860 - val_accuracy: 0.4316\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.6312 - accuracy: 0.5079 - val_loss: 1.7404 - val_accuracy: 0.4421\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.3405 - accuracy: 0.5340 - val_loss: 1.5481 - val_accuracy: 0.4842\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.0292 - accuracy: 0.6963 - val_loss: 1.3958 - val_accuracy: 0.5895\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.7457 - accuracy: 0.8534 - val_loss: 1.5156 - val_accuracy: 0.5368\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.5053 - accuracy: 0.9162 - val_loss: 1.3372 - val_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.3874 - accuracy: 0.9215 - val_loss: 1.4244 - val_accuracy: 0.6316\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2933 - accuracy: 0.9581 - val_loss: 1.2898 - val_accuracy: 0.6211\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1775 - accuracy: 0.9791 - val_loss: 1.6168 - val_accuracy: 0.6105\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1203 - accuracy: 0.9895 - val_loss: 1.3692 - val_accuracy: 0.5789\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0784 - accuracy: 0.9895 - val_loss: 1.5935 - val_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0565 - accuracy: 0.9948 - val_loss: 1.7203 - val_accuracy: 0.6105\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0357 - accuracy: 0.9948 - val_loss: 1.5329 - val_accuracy: 0.6105\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0289 - accuracy: 0.9948 - val_loss: 1.7871 - val_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.8843 - val_accuracy: 0.6105\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.7713 - val_accuracy: 0.6105\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.7589 - val_accuracy: 0.6105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d86806a700>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model7 = Sequential()\n",
    "Model7.add(Embedding(input_dim = len(Tr.word_index)+1,output_dim =100,weights = [embedding_matrix_Word2vec_Self],input_length=19))\n",
    "Model7.add(GRU(100))\n",
    "Model7.add(Dense(100,activation='relu'))\n",
    "Model7.add(Dense(50,activation='relu'))\n",
    "Model7.add(Dense(8,activation='softmax'))\n",
    "Model7.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "ES = EarlyStopping(monitor='val_accuracy',min_delta=0.0001,patience=10,mode='max')\n",
    "Model7.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "433c61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_7 = Model7.predict(X_test)\n",
    "value,classes_pred = tf.math.top_k(prediction_7,k=1, sorted=True, name=None)\n",
    "classes_actual = y_test.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "40b68c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.50      0.44        12\n",
      "           1       0.57      0.44      0.50         9\n",
      "           2       0.35      0.67      0.46        12\n",
      "           3       0.80      0.86      0.83        14\n",
      "           4       1.00      0.46      0.63        13\n",
      "           5       0.79      1.00      0.88        11\n",
      "           6       0.80      0.36      0.50        11\n",
      "           7       0.70      0.54      0.61        13\n",
      "\n",
      "    accuracy                           0.61        95\n",
      "   macro avg       0.68      0.60      0.61        95\n",
      "weighted avg       0.68      0.61      0.61        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes_actual,classes_pred.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9228a8d",
   "metadata": {},
   "source": [
    "# Model8 : GRU with Word2Vec Pre trained embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6e83b438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 2s 95ms/step - loss: 2.0788 - accuracy: 0.1257 - val_loss: 2.0752 - val_accuracy: 0.1368\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 2.0656 - accuracy: 0.3351 - val_loss: 2.0628 - val_accuracy: 0.2632\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.0360 - accuracy: 0.3613 - val_loss: 2.0366 - val_accuracy: 0.3053\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.9754 - accuracy: 0.4241 - val_loss: 1.9865 - val_accuracy: 0.3053\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.8560 - accuracy: 0.4241 - val_loss: 1.8852 - val_accuracy: 0.3368\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.6564 - accuracy: 0.4346 - val_loss: 1.7520 - val_accuracy: 0.4000\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.4309 - accuracy: 0.5183 - val_loss: 1.6490 - val_accuracy: 0.4526\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.1416 - accuracy: 0.6545 - val_loss: 1.4954 - val_accuracy: 0.4842\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.8371 - accuracy: 0.8063 - val_loss: 1.4397 - val_accuracy: 0.5158\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.5731 - accuracy: 0.8691 - val_loss: 1.3993 - val_accuracy: 0.5579\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.4170 - accuracy: 0.8848 - val_loss: 1.6401 - val_accuracy: 0.5684\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2813 - accuracy: 0.9319 - val_loss: 1.5037 - val_accuracy: 0.5789\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.2126 - accuracy: 0.9476 - val_loss: 1.8763 - val_accuracy: 0.5789\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1542 - accuracy: 0.9843 - val_loss: 1.6721 - val_accuracy: 0.5895\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.1020 - accuracy: 0.9948 - val_loss: 1.8310 - val_accuracy: 0.5895\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0651 - accuracy: 0.9948 - val_loss: 1.8719 - val_accuracy: 0.5789\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 1.9534 - val_accuracy: 0.5789\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 2.0133 - val_accuracy: 0.5684\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.0782 - val_accuracy: 0.5789\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.1538 - val_accuracy: 0.5789\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.1624 - val_accuracy: 0.5789\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.1985 - val_accuracy: 0.5789\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.2738 - val_accuracy: 0.5789\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.2872 - val_accuracy: 0.5789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d86c63ed00>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model8 = Sequential()\n",
    "Model8.add(Embedding(input_dim = len(Tr.word_index)+1,output_dim =100,weights = [embedding_matrix_Word2vec_Self],input_length=19))\n",
    "Model8.add(GRU(100))\n",
    "Model8.add(Dense(100,activation='relu'))\n",
    "Model8.add(Dense(50,activation='relu'))\n",
    "Model8.add(Dense(8,activation='softmax'))\n",
    "Model8.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "ES = EarlyStopping(monitor='val_accuracy',min_delta=0.0001,patience=10,mode='max')\n",
    "Model8.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c3e78fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_8 = Model8.predict(X_test)\n",
    "value,classes_pred = tf.math.top_k(prediction_8,k=1, sorted=True, name=None)\n",
    "classes_actual = y_test.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "02a9d0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.42      0.34        12\n",
      "           1       0.75      0.33      0.46         9\n",
      "           2       0.38      0.42      0.40        12\n",
      "           3       0.75      0.86      0.80        14\n",
      "           4       0.44      0.62      0.52        13\n",
      "           5       0.92      1.00      0.96        11\n",
      "           6       0.75      0.27      0.40        11\n",
      "           7       0.73      0.62      0.67        13\n",
      "\n",
      "    accuracy                           0.58        95\n",
      "   macro avg       0.63      0.57      0.57        95\n",
      "weighted avg       0.62      0.58      0.57        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes_actual,classes_pred.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c0643",
   "metadata": {},
   "source": [
    "# Model9 : GRU with GloVe Pre trained embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "586cc0c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 2s 96ms/step - loss: 2.0790 - accuracy: 0.1623 - val_loss: 2.0773 - val_accuracy: 0.2211\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 2.0649 - accuracy: 0.2565 - val_loss: 2.0686 - val_accuracy: 0.1474\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 2.0371 - accuracy: 0.2618 - val_loss: 2.0477 - val_accuracy: 0.2421\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.9803 - accuracy: 0.3927 - val_loss: 2.0103 - val_accuracy: 0.2526\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.8669 - accuracy: 0.4136 - val_loss: 1.9438 - val_accuracy: 0.2737\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.6951 - accuracy: 0.3822 - val_loss: 1.8303 - val_accuracy: 0.3263\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.4548 - accuracy: 0.5969 - val_loss: 1.6685 - val_accuracy: 0.4526\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.1713 - accuracy: 0.6649 - val_loss: 1.5006 - val_accuracy: 0.5368\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.8730 - accuracy: 0.7644 - val_loss: 1.3834 - val_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6343 - accuracy: 0.8848 - val_loss: 1.5167 - val_accuracy: 0.5684\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.4447 - accuracy: 0.9058 - val_loss: 1.4116 - val_accuracy: 0.6316\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.3084 - accuracy: 0.9581 - val_loss: 1.5856 - val_accuracy: 0.5684\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2322 - accuracy: 0.9581 - val_loss: 1.5357 - val_accuracy: 0.6316\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1488 - accuracy: 0.9791 - val_loss: 1.6790 - val_accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1040 - accuracy: 0.9843 - val_loss: 1.7586 - val_accuracy: 0.6526\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0816 - accuracy: 0.9948 - val_loss: 1.9433 - val_accuracy: 0.5789\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0628 - accuracy: 0.9948 - val_loss: 1.8423 - val_accuracy: 0.6316\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0491 - accuracy: 0.9948 - val_loss: 1.9349 - val_accuracy: 0.6316\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 1.9644 - val_accuracy: 0.6000\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.0458 - val_accuracy: 0.6211\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.1269 - val_accuracy: 0.6316\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.1911 - val_accuracy: 0.6211\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.2074 - val_accuracy: 0.6421\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.2185 - val_accuracy: 0.6421\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.2625 - val_accuracy: 0.6421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d870b71e80>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model9 = Sequential()\n",
    "Model9.add(Embedding(input_dim = len(Tr.word_index)+1,output_dim =100,weights = [embedding_matrix_Word2vec_Self],input_length=19))\n",
    "Model9.add(GRU(100))\n",
    "Model9.add(Dense(100,activation='relu'))\n",
    "Model9.add(Dense(50,activation='relu'))\n",
    "Model9.add(Dense(8,activation='softmax'))\n",
    "Model9.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "ES = EarlyStopping(monitor='val_accuracy',min_delta=0.0001,patience=10,mode='max')\n",
    "Model9.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e5e2d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_9 = Model9.predict(X_test)\n",
    "value,classes_pred = tf.math.top_k(prediction_9,k=1, sorted=True, name=None)\n",
    "classes_actual = y_test.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c80ee85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.33      0.43         9\n",
      "           1       0.53      0.69      0.60        13\n",
      "           2       0.31      0.82      0.45        11\n",
      "           3       1.00      0.89      0.94         9\n",
      "           4       0.90      0.64      0.75        14\n",
      "           5       0.92      0.79      0.85        14\n",
      "           6       0.50      0.18      0.27        11\n",
      "           7       1.00      0.71      0.83        14\n",
      "\n",
      "    accuracy                           0.64        95\n",
      "   macro avg       0.72      0.63      0.64        95\n",
      "weighted avg       0.73      0.64      0.65        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes_actual,classes_pred.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418273cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
