{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOf1HHiDog86"
   },
   "source": [
    "## Importing the Libraries and also python install the openAI package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOn5XUbx1oeV",
    "outputId": "ef45d33b-34b8-414a-c19f-a9cca924eb31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "# !pip install --upgrade openai\n",
    "# !pip install wandb\n",
    "drive.mount('/content/drive/')\n",
    "project_path = '/content/drive/My Drive/Data Science/GPT3/'\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7uddF8donSi"
   },
   "source": [
    "## Loading the dataset and adding seperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "cpxxbyTr2sjK"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(project_path+'sample_snps_data.csv')\n",
    "df.drop('case_id',axis=1,inplace=True)\n",
    "df.rename(columns = {'q7':'prompt','q6':'completion'}, inplace = True)\n",
    "df.to_json(project_path+\"data.jsonl\", orient='records', lines=True)\n",
    "\n",
    "def add_seperator(x):\n",
    "  return x+\" -> \"\n",
    "\n",
    "df['prompt'] = df.apply(lambda x: add_seperator(x['prompt']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "UpwjZer0QALw",
    "outputId": "fd8c3922-ab38-4dcf-f07c-31fdbdb52090"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'All I keep hearing is I can not help you.  I have been put off and hung up on.   All I want go do is cancel my HP smart friend account. I am done with hp! -> '"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prompt.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIHupszKp58i"
   },
   "source": [
    "## Converting the Dataframe to a JSON format - to be loaded to GPT3 Model\n",
    "\n",
    "1. \"!openai\" (Openai Package) \n",
    "\n",
    "2. \"tools fine_tunes.prepare_data\" (call prepare_data method to prepare the data in json format and  for finetuning the GPT3 model )\n",
    "\n",
    "3. -f (File path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDFoY5Td3QAS",
    "outputId": "4d8b76f1-86e7-4916-bacb-919b2a5c0eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 1000 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- There are 1 duplicated prompt-completion sets. These are rows: [663]\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 1 duplicate rows [Y/n]: Y\n",
      "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
      "/usr/local/lib/python3.7/dist-packages/openai/validators.py:215: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[\"prompt\"] += suffix\n",
      "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
      "/usr/local/lib/python3.7/dist-packages/openai/validators.py:415: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lambda x: (\"\" if x[0] == \" \" else \" \") + x\n",
      "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified files to `/content/drive/My Drive/Data Science/GPT3/data_prepared_train (1).jsonl` and `/content/drive/My Drive/Data Science/GPT3/data_prepared_valid (1).jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"/content/drive/My Drive/Data Science/GPT3/data_prepared_train (1).jsonl\" -v \"/content/drive/My Drive/Data Science/GPT3/data_prepared_valid (1).jsonl\" --compute_classification_metrics --classification_n_classes 3\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt.\n",
      "Once your model starts training, it'll approximately take 26.31 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f \"/content/drive/My Drive/Data Science/GPT3/data.jsonl\" -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kqTaOMoq6i7"
   },
   "source": [
    "# **Fine tuning GPT3**\n",
    "1. !openai -> calling open ai\n",
    "2. -k -> Sharing the API key\n",
    "3. api fine_tunes.create  ->  Using the API fine tune GPT3\n",
    "4. -t  -> Training data location\n",
    "5. -v  -> Validation data\n",
    "6. -m  -> Base model type\n",
    "7. --compute_classification_metrics   -> Computing classification report\n",
    "8. --classification_n_classes 3  -> Using 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phPjvHPs4dv9",
    "outputId": "eaabae7f-2acc-4d30-92e5-c74c73a0e23a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found potentially duplicated files with name 'data_prepared_train.jsonl', purpose 'fine-tune' and size 324112 bytes\n",
      "file-YnC4gk1VuNKvVwvlWP5HtXG7\n",
      "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: YnC4gk1VuNKvVwvlWP5HtXG7\n",
      "File id 'YnC4gk1VuNKvVwvlWP5HtXG7' is not among the IDs of the potentially duplicated files\n",
      "\n",
      "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: file-YnC4gk1VuNKvVwvlWP5HtXG7\n",
      "Reusing already uploaded file: file-YnC4gk1VuNKvVwvlWP5HtXG7\n",
      "Upload progress: 100% 85.9k/85.9k [00:00<00:00, 152Mit/s]\n",
      "Uploaded file from /content/drive/My Drive/Data Science/GPT3/data_prepared_valid.jsonl: file-infRk9VHi6wEy33sWFpfYNvk\n",
      "Created fine-tune: ft-U8Xkz19BrpE5RwUma9FBulOD\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2022-07-28 06:29:15] Created fine-tune: ft-U8Xkz19BrpE5RwUma9FBulOD\n",
      "[2022-07-28 06:29:22] Fine-tune costs $0.11\n",
      "[2022-07-28 06:29:22] Fine-tune enqueued. Queue number: 0\n",
      "[2022-07-28 06:29:23] Fine-tune started\n",
      "[2022-07-28 06:31:31] Completed epoch 1/4\n",
      "[2022-07-28 06:33:30] Completed epoch 2/4\n",
      "[2022-07-28 06:35:27] Completed epoch 3/4\n",
      "[2022-07-28 06:37:25] Completed epoch 4/4\n",
      "[2022-07-28 06:37:48] Uploaded model: ada:ft-student-2022-07-28-06-37-48\n",
      "[2022-07-28 06:37:49] Uploaded result file: file-yESu9Z3DFQoPTh7sCQ4JGUJt\n",
      "[2022-07-28 06:37:49] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded ðŸŽ‰\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m ada:ft-student-2022-07-28-06-37-48 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "# !export OPENAI_API_KEY= \"Your - API key\"\n",
    "# !export OPENAI_API_KEY= \"Your - API key\"\n",
    "\n",
    "!openai -k \"Your - API key\" api fine_tunes.create -t \"/content/drive/My Drive/Data Science/GPT3/data_prepared_train.jsonl\" -v \"/content/drive/My Drive/Data Science/GPT3/data_prepared_valid.jsonl\" -m ada --batch_size --compute_classification_metrics --classification_n_classes 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "hwEM2otxcMeU"
   },
   "outputs": [],
   "source": [
    "!openai -k \"Your - API key\" api fine_tunes.results -i ft-U8Xkz19BrpE5RwUma9FBulOD > result.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvwfTM_Ub-Z6",
    "outputId": "eb32beef-f5b1-454c-f428-ad10552d666f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I dint get a good resolution -> detractor -> detractor detractor detractor detractor detractor detractor detract"
     ]
    }
   ],
   "source": [
    "!openai -k \"Your - API key\" api completions.create -m ada:ft-student-2022-07-28-06-37-48 -p \"I dint get a good resolution ->\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "t7-YHmpOieOO",
    "outputId": "ddb3b6df-687c-4556-f766-041c0c2bfc1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-be07c416-f439-4e19-8058-fc7cf43d5ea7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>elapsed_tokens</th>\n",
       "      <th>elapsed_examples</th>\n",
       "      <th>training_loss</th>\n",
       "      <th>training_sequence_accuracy</th>\n",
       "      <th>training_token_accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_sequence_accuracy</th>\n",
       "      <th>validation_token_accuracy</th>\n",
       "      <th>classification/accuracy</th>\n",
       "      <th>classification/weighted_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>3197</td>\n",
       "      <td>278437</td>\n",
       "      <td>3197</td>\n",
       "      <td>0.134664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.858391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be07c416-f439-4e19-8058-fc7cf43d5ea7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-be07c416-f439-4e19-8058-fc7cf43d5ea7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-be07c416-f439-4e19-8058-fc7cf43d5ea7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      step  elapsed_tokens  elapsed_examples  training_loss  \\\n",
       "3196  3197          278437              3197       0.134664   \n",
       "\n",
       "      training_sequence_accuracy  training_token_accuracy  validation_loss  \\\n",
       "3196                         1.0                      1.0              NaN   \n",
       "\n",
       "      validation_sequence_accuracy  validation_token_accuracy  \\\n",
       "3196                           NaN                        NaN   \n",
       "\n",
       "      classification/accuracy  classification/weighted_f1_score  \n",
       "3196                    0.885                          0.858391  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv('result.csv')\n",
    "results[results['classification/accuracy'].notnull()].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythonese version of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nP9VyMDTifRc",
    "outputId": "8e22226a-cc46-4447-d435-0169454bda13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5YrdVPevwFxqjoRRxi5XJJg8UXcoc at 0x7f8a960598f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" detractor detractor detractor detractor detractor detractor detractor detractor\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1658991013,\n",
       "  \"id\": \"cmpl-5YrdVPevwFxqjoRRxi5XJJg8UXcoc\",\n",
       "  \"model\": \"ada:ft-student-2022-07-28-05-56-26\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 16,\n",
       "    \"prompt_tokens\": 8,\n",
       "    \"total_tokens\": 24\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key = 'Your - API key'\n",
    "ft_model = 'ada:ft-student-2022-07-28-05-56-26'\n",
    "openai.Completion.create(model=ft_model, prompt=\"I dint get a good resolution ->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "0DdPJl7mkDEV"
   },
   "outputs": [],
   "source": [
    "result = openai.Completion.create(model=ft_model, prompt=\"I purchased the computer June 2017, it has been working well until now. ->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "bFrPbwWhkwe_",
    "outputId": "71a9f93f-b1a8-4295-f5b1-9541e725681b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' passive p'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['choices'][0]['text'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fN0bX4jUk118"
   },
   "source": [
    "# Key things to watchout in the documentation:\n",
    "\n",
    "### The seperator does not fit in even if provided. It uses the default seperator \" ->\"  - Check documentation\n",
    "\n",
    "### The classes predicted gets repeated multiple times - Check documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "GPT 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
